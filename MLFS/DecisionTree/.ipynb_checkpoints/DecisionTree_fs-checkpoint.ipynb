{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "### From scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive partition of the dataset generating interior nodes. The leafs are attached to a simple model to predict the response.\n",
    "\n",
    "For classification the predicted value is the mode of the dependent variable in that leaf.  \n",
    "For regression is the mean of the dependent variable in that leaf:\n",
    "\n",
    "$ \\large d = (x_1, y_1),(x_2, y_2), . . .(x_n, y_n) $  \n",
    "$ \\large \\hat{y} = \\frac{1}{n} \\sum_{i=1}^n y_i $\n",
    "\n",
    "Scores can be calculated standardizing the regression results (normally distributed with 0 mean and 1 variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ![](dt.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key of the decision tree model is the recursive partition strategy. There are several approaches:   \n",
    "base the split on optimizing Gini Index, Cross-Entropy or minimizing variance. \n",
    "Here we will develop a decision tree from scratch using Gini Index in four steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Gini Index\n",
    "2. Create Split\n",
    "3. Build a Tree\n",
    "4. Make a Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Gini Index\n",
    "A Gini score gives an idea of how good a split is by how mixed the classes are in the two groups created by the split.  \n",
    "A perfect separation results in a Gini score of 0, whereas the worst case split that results in 50/50 classes in each group result in a Gini score of 0.5 (for a 2 class problem).\n",
    "\n",
    "So, for a binary classification problem, the formula is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\large  G = \\sum_{i=1}^M p \\; (1-p) \\; \\Rightarrow \\; G = 1- \\sum_{i=1}^M p^2 $\n",
    "\n",
    "where $p$ = proportion = count(class) / count(rows)\n",
    "\n",
    "If we have two groups (e.g. leafs) and two classes \n",
    "\n",
    "$ \\large g_1(c_1) = 2/2 = 1 $  \n",
    "$ \\large g_1(c_2) = 0/2 = 0  $  \n",
    "$ \\large g_2(c_1) = 0/2 = 0  $  \n",
    "$ \\large g_2(c_2) = 2/2 = 1  $\n",
    "\n",
    "Then Gini is:\n",
    "\n",
    "Gini(g1) = (1 - (1x1 + 0x0)) x 2/4 = 0  \n",
    "Gini(g2) = (1 - (0x0 + 1x1)) x 2/4 = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gini index for a split dataset\n",
    "def gini_index(groups, classes):\n",
    "    n = float(sum([len(group) for group in groups]))\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0: continue\n",
    "        score = 0.0\n",
    "        for c in classes:\n",
    "            propByClass = [row[-1] for row in group].count(c) / size \n",
    "            score += propByClass * propByClass\n",
    "        gini += (1.0 - score) * (size / n) # weight by relative size\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gini indexes:   Group 1:  0.5  Group 2:  0.5\n",
      "Gini indexes:   Group 1:  0.0  Group 2:  0.0\n"
     ]
    }
   ],
   "source": [
    "group1 = [[1, 1], [1, 0]]\n",
    "group2 = [[1, 1], [1, 0]]\n",
    "classes = [0, 1]\n",
    "gini = gini_index([group1, group2], classes)\n",
    "print('Gini indexes: ', ' Group 1: ', gini, ' Group 2: ', gini)\n",
    "group1 = [[1, 0], [1, 0]]\n",
    "group2 = [[1, 1], [1, 1]]\n",
    "classes = [0, 1]\n",
    "gini = gini_index([group1, group2], classes)\n",
    "print('Gini indexes: ', ' Group 1: ', gini, ' Group 2: ', gini)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset based on an attribute and an attribute value\n",
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right\n",
    "\n",
    "\n",
    "# Select the best split point for a dataset\n",
    "def get_basic_split(dataset):\n",
    "    classes = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, classes)\n",
    "            print('X%d < %.3f Gini=%.3f' % ((index+1), row[index], gini))\n",
    "            if gini < b_score:\n",
    "                b_index, b_value, b_score, b_groups = index, row[index], gini, groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1 < 2.771 Gini=0.444\n",
      "X1 < 1.729 Gini=0.500\n",
      "X1 < 3.678 Gini=0.286\n",
      "X1 < 3.961 Gini=0.167\n",
      "X1 < 2.999 Gini=0.375\n",
      "X1 < 7.498 Gini=0.286\n",
      "X1 < 9.002 Gini=0.375\n",
      "X1 < 7.445 Gini=0.167\n",
      "X1 < 10.125 Gini=0.444\n",
      "X1 < 6.642 Gini=0.000\n",
      "X2 < 1.785 Gini=0.500\n",
      "X2 < 1.170 Gini=0.444\n",
      "X2 < 2.813 Gini=0.320\n",
      "X2 < 2.620 Gini=0.417\n",
      "X2 < 2.209 Gini=0.476\n",
      "X2 < 3.163 Gini=0.167\n",
      "X2 < 3.339 Gini=0.444\n",
      "X2 < 0.477 Gini=0.500\n",
      "X2 < 3.235 Gini=0.286\n",
      "X2 < 3.320 Gini=0.375\n",
      "2\n",
      "Split: [X1 < 6.642]\n"
     ]
    }
   ],
   "source": [
    "ds = [[2.771244718,1.784783929,0],\n",
    "      [1.728571309,1.169761413,0],\n",
    "      [3.678319846,2.81281357,0],\n",
    "      [3.961043357,2.61995032,0],\n",
    "      [2.999208922,2.209014212,0],\n",
    "      [7.497545867,3.162953546,1],\n",
    "      [9.00220326,3.339047188,1],\n",
    "      [7.444542326,0.476683375,1],\n",
    "      [10.12493903,3.234550982,1],\n",
    "      [6.642287351,3.319983761,1]]\n",
    "\n",
    "split = get_basic_split(ds)\n",
    "print(len(ds[0])-1)\n",
    "print('Split: [X%d < %.3f]' % ((split['index']+1), split['value']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits & Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/implement-decision-tree-algorithm-scratch-python/  \n",
    "https://medium.com/@penggongting/implementing-decision-tree-from-scratch-in-python-c732e7c69aea\n",
    "https://www.saedsayad.com/decision_tree_reg.htm\n",
    "http://www.stat.cmu.edu/~cshalizi/350-2006/lecture-10.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
