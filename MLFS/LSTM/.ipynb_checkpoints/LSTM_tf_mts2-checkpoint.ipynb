{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM for Time Series\n",
    "### With TensorFlow/Keras: Multivariate time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from math import sqrt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow.keras.models as tkm\n",
    "import tensorflow.keras.layers as tkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and transform dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pollution</th>\n",
       "      <th>dew</th>\n",
       "      <th>temp</th>\n",
       "      <th>press</th>\n",
       "      <th>wnd_dir</th>\n",
       "      <th>wnd_spd</th>\n",
       "      <th>snow</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-02 00:00:00</th>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 01:00:00</th>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 02:00:00</th>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 03:00:00</th>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-02 04:00:00</th>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     pollution  dew  temp   press wnd_dir  wnd_spd  snow  rain\n",
       "date                                                                          \n",
       "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0     0\n",
       "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0     0\n",
       "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0     0\n",
       "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1     0\n",
       "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2     0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('D:/data/csv/pollution.csv', header=0, index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43800, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ds(mts, n_in=1, n_out=1, dropnan=True):\n",
    "    nvars = mts.shape[1]\n",
    "    cols, names = list(), list()\n",
    "    \n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(mts.shift(i, axis=0))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(nvars)]\n",
    "    \n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(mts.shift(-i, axis=0))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(nvars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(nvars)]\n",
    "    \n",
    "    ds = pd.concat(cols, axis=1)\n",
    "    ds.columns = names\n",
    "    if dropnan:\n",
    "        ds.dropna(inplace=True)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mts = data.values\n",
    "encoder = LabelEncoder()\n",
    "mts[:,4] = encoder.fit_transform(mts[:,4])\n",
    "mts = mts.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43800, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "mts_sc = scaler.fit_transform(mts)\n",
    "len(mts_sc), len(mts_sc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var6(t-2)</th>\n",
       "      <th>var7(t-2)</th>\n",
       "      <th>var8(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>...</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "      <th>var4(t)</th>\n",
       "      <th>var5(t)</th>\n",
       "      <th>var6(t)</th>\n",
       "      <th>var7(t)</th>\n",
       "      <th>var8(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.129779</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105634</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.581818</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.014492</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var6(t-2)  \\\n",
       "2   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
       "3   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
       "4   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
       "5   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
       "6   0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
       "\n",
       "   var7(t-2)  var8(t-2)  var1(t-1)  var2(t-1)  ...  var7(t-1)  var8(t-1)  \\\n",
       "2   0.000000        0.0   0.148893   0.367647  ...   0.000000        0.0   \n",
       "3   0.000000        0.0   0.159960   0.426471  ...   0.000000        0.0   \n",
       "4   0.000000        0.0   0.182093   0.485294  ...   0.037037        0.0   \n",
       "5   0.037037        0.0   0.138833   0.485294  ...   0.074074        0.0   \n",
       "6   0.074074        0.0   0.109658   0.485294  ...   0.111111        0.0   \n",
       "\n",
       "    var1(t)   var2(t)   var3(t)   var4(t)   var5(t)   var6(t)   var7(t)  \\\n",
       "2  0.159960  0.426471  0.229508  0.545454  0.666667  0.005332  0.000000   \n",
       "3  0.182093  0.485294  0.229508  0.563637  0.666667  0.008391  0.037037   \n",
       "4  0.138833  0.485294  0.229508  0.563637  0.666667  0.009912  0.074074   \n",
       "5  0.109658  0.485294  0.213115  0.563637  0.666667  0.011433  0.111111   \n",
       "6  0.105634  0.485294  0.213115  0.581818  0.666667  0.014492  0.148148   \n",
       "\n",
       "   var8(t)  \n",
       "2      0.0  \n",
       "3      0.0  \n",
       "4      0.0  \n",
       "5      0.0  \n",
       "6      0.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mts_sc = pd.DataFrame(mts_sc)\n",
    "ds_comp = build_ds(mts_sc, 2, 1)\n",
    "ds_comp.shape\n",
    "ds_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43798, 24)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_comp.columns\n",
    "ds_comp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-2)</th>\n",
       "      <th>var2(t-2)</th>\n",
       "      <th>var3(t-2)</th>\n",
       "      <th>var4(t-2)</th>\n",
       "      <th>var5(t-2)</th>\n",
       "      <th>var6(t-2)</th>\n",
       "      <th>var7(t-2)</th>\n",
       "      <th>var8(t-2)</th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var4(t-1)</th>\n",
       "      <th>var5(t-1)</th>\n",
       "      <th>var6(t-1)</th>\n",
       "      <th>var7(t-1)</th>\n",
       "      <th>var8(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.129779</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.002290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148893</td>\n",
       "      <td>0.367647</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.003811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.159960</td>\n",
       "      <td>0.426471</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.182093</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.138833</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.229508</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109658</td>\n",
       "      <td>0.485294</td>\n",
       "      <td>0.213115</td>\n",
       "      <td>0.563637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-2)  var2(t-2)  var3(t-2)  var4(t-2)  var5(t-2)  var6(t-2)  \\\n",
       "2   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
       "3   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
       "4   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
       "5   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
       "6   0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
       "\n",
       "   var7(t-2)  var8(t-2)  var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  \\\n",
       "2   0.000000        0.0   0.148893   0.367647   0.245902   0.527273   \n",
       "3   0.000000        0.0   0.159960   0.426471   0.229508   0.545454   \n",
       "4   0.000000        0.0   0.182093   0.485294   0.229508   0.563637   \n",
       "5   0.037037        0.0   0.138833   0.485294   0.229508   0.563637   \n",
       "6   0.074074        0.0   0.109658   0.485294   0.213115   0.563637   \n",
       "\n",
       "   var5(t-1)  var6(t-1)  var7(t-1)  var8(t-1)   var1(t)  \n",
       "2   0.666667   0.003811   0.000000        0.0  0.159960  \n",
       "3   0.666667   0.005332   0.000000        0.0  0.182093  \n",
       "4   0.666667   0.008391   0.037037        0.0  0.138833  \n",
       "5   0.666667   0.009912   0.074074        0.0  0.109658  \n",
       "6   0.666667   0.011433   0.111111        0.0  0.105634  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = ds_comp\n",
    "ds.drop(ds.columns[17:24], axis=1, inplace=True) \n",
    "ds.head()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['var1(t-2)', 'var2(t-2)', 'var3(t-2)', 'var4(t-2)', 'var5(t-2)',\n",
       "       'var6(t-2)', 'var7(t-2)', 'var8(t-2)', 'var1(t-1)', 'var2(t-1)',\n",
       "       'var3(t-1)', 'var4(t-1)', 'var5(t-1)', 'var6(t-1)', 'var7(t-1)',\n",
       "       'var8(t-1)', 'var1(t)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test / inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8760, 1, 16) (8760,) (35038, 1, 16) (35038,)\n",
      "[[[0.12977867 0.35294122 0.24590163 0.5272732  0.6666667  0.00229001\n",
      "   0.         0.         0.14889336 0.36764708 0.24590163 0.5272732\n",
      "   0.6666667  0.00381099 0.         0.        ]]\n",
      "\n",
      " [[0.14889336 0.36764708 0.24590163 0.5272732  0.6666667  0.00381099\n",
      "   0.         0.         0.15995975 0.4264706  0.22950819 0.545454\n",
      "   0.6666667  0.00533197 0.         0.        ]]\n",
      "\n",
      " [[0.15995975 0.4264706  0.22950819 0.545454   0.6666667  0.00533197\n",
      "   0.         0.         0.18209255 0.48529413 0.22950819 0.5636368\n",
      "   0.6666667  0.00839101 0.03703704 0.        ]]\n",
      "\n",
      " [[0.18209255 0.48529413 0.22950819 0.5636368  0.6666667  0.00839101\n",
      "   0.03703704 0.         0.13883299 0.48529413 0.22950819 0.5636368\n",
      "   0.6666667  0.00991199 0.07407407 0.        ]]\n",
      "\n",
      " [[0.13883299 0.48529413 0.22950819 0.5636368  0.6666667  0.00991199\n",
      "   0.07407407 0.         0.10965794 0.48529413 0.21311474 0.5636368\n",
      "   0.6666667  0.01143297 0.11111111 0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "values = ds.values\n",
    "n_train_hours = 365*24\n",
    "ds_train = values[:n_train_hours, :]\n",
    "ds_test = values[n_train_hours:, :]\n",
    "\n",
    "X_train, y_train = ds_train[:, :-1], ds_train[:, -1]\n",
    "X_test, y_test = ds_test[:, :-1], ds_test[:, -1]\n",
    "\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "print(X_train[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "122/122 - 1s - loss: 0.0528 - val_loss: 0.0488\n",
      "Epoch 2/50\n",
      "122/122 - 1s - loss: 0.0271 - val_loss: 0.0391\n",
      "Epoch 3/50\n",
      "122/122 - 1s - loss: 0.0194 - val_loss: 0.0255\n",
      "Epoch 4/50\n",
      "122/122 - 1s - loss: 0.0178 - val_loss: 0.0181\n",
      "Epoch 5/50\n",
      "122/122 - 1s - loss: 0.0170 - val_loss: 0.0169\n",
      "Epoch 6/50\n",
      "122/122 - 1s - loss: 0.0173 - val_loss: 0.0169\n",
      "Epoch 7/50\n",
      "122/122 - 1s - loss: 0.0167 - val_loss: 0.0161\n",
      "Epoch 8/50\n",
      "122/122 - 1s - loss: 0.0169 - val_loss: 0.0162\n",
      "Epoch 9/50\n",
      "122/122 - 1s - loss: 0.0162 - val_loss: 0.0158\n",
      "Epoch 10/50\n",
      "122/122 - 1s - loss: 0.0162 - val_loss: 0.0159\n",
      "Epoch 11/50\n",
      "122/122 - 1s - loss: 0.0163 - val_loss: 0.0158\n",
      "Epoch 12/50\n",
      "122/122 - 1s - loss: 0.0159 - val_loss: 0.0153\n",
      "Epoch 13/50\n",
      "122/122 - 1s - loss: 0.0162 - val_loss: 0.0157\n",
      "Epoch 14/50\n",
      "122/122 - 1s - loss: 0.0155 - val_loss: 0.0149\n",
      "Epoch 15/50\n",
      "122/122 - 1s - loss: 0.0159 - val_loss: 0.0154\n",
      "Epoch 16/50\n",
      "122/122 - 1s - loss: 0.0153 - val_loss: 0.0154\n",
      "Epoch 17/50\n",
      "122/122 - 1s - loss: 0.0153 - val_loss: 0.0152\n",
      "Epoch 18/50\n",
      "122/122 - 1s - loss: 0.0154 - val_loss: 0.0149\n",
      "Epoch 19/50\n",
      "122/122 - 1s - loss: 0.0151 - val_loss: 0.0147\n",
      "Epoch 20/50\n",
      "122/122 - 1s - loss: 0.0153 - val_loss: 0.0147\n",
      "Epoch 21/50\n",
      "122/122 - 1s - loss: 0.0150 - val_loss: 0.0151\n",
      "Epoch 22/50\n",
      "122/122 - 1s - loss: 0.0150 - val_loss: 0.0149\n",
      "Epoch 23/50\n",
      "122/122 - 1s - loss: 0.0150 - val_loss: 0.0148\n",
      "Epoch 24/50\n",
      "122/122 - 1s - loss: 0.0149 - val_loss: 0.0149\n",
      "Epoch 25/50\n",
      "122/122 - 1s - loss: 0.0148 - val_loss: 0.0148\n",
      "Epoch 26/50\n",
      "122/122 - 1s - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 27/50\n",
      "122/122 - 1s - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 28/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 29/50\n",
      "122/122 - 1s - loss: 0.0147 - val_loss: 0.0148\n",
      "Epoch 30/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0154\n",
      "Epoch 31/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0148\n",
      "Epoch 32/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0150\n",
      "Epoch 33/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 34/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0149\n",
      "Epoch 35/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 36/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0151\n",
      "Epoch 37/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 38/50\n",
      "122/122 - 1s - loss: 0.0145 - val_loss: 0.0149\n",
      "Epoch 39/50\n",
      "122/122 - 1s - loss: 0.0145 - val_loss: 0.0151\n",
      "Epoch 40/50\n",
      "122/122 - 1s - loss: 0.0145 - val_loss: 0.0150\n",
      "Epoch 41/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0146\n",
      "Epoch 42/50\n",
      "122/122 - 1s - loss: 0.0144 - val_loss: 0.0153\n",
      "Epoch 43/50\n",
      "122/122 - 1s - loss: 0.0146 - val_loss: 0.0148\n",
      "Epoch 44/50\n",
      "122/122 - 1s - loss: 0.0144 - val_loss: 0.0146\n",
      "Epoch 45/50\n",
      "122/122 - 1s - loss: 0.0145 - val_loss: 0.0147\n",
      "Epoch 46/50\n",
      "122/122 - 1s - loss: 0.0144 - val_loss: 0.0148\n",
      "Epoch 47/50\n",
      "122/122 - 1s - loss: 0.0145 - val_loss: 0.0149\n",
      "Epoch 48/50\n",
      "122/122 - 1s - loss: 0.0144 - val_loss: 0.0152\n",
      "Epoch 49/50\n",
      "122/122 - 1s - loss: 0.0145 - val_loss: 0.0149\n",
      "Epoch 50/50\n",
      "122/122 - 1s - loss: 0.0143 - val_loss: 0.0155\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = tkm.Sequential()\n",
    "model.add(tkl.LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(tkl.Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=72, validation_data=(X_test, y_test), verbose=2, shuffle=False)\n",
    "\n",
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1082 predict_function  *\n        outputs = self.distribute_strategy.run(\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1057 predict_step  **\n        return self(x, training=False)\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:884 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 16]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-133-9ba6ac303f80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     86\u001b[0m           method.__name__))\n\u001b[1;32m---> 87\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1201\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1203\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1204\u001b[0m             \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m             \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    616\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 618\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    619\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2417\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2419\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2420\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2772\u001b[0m           \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2773\u001b[0m           and call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 2774\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_define_function_with_shape_relaxation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2703\u001b[0m     self._function_cache.arg_relaxed_shapes[rank_only_cache_key] = (\n\u001b[0;32m   2704\u001b[0m         relaxed_arg_shapes)\n\u001b[1;32m-> 2705\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   2706\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   2707\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 2657\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    439\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    966\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 968\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1082 predict_function  *\n        outputs = self.distribute_strategy.run(\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:951 run  **\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2290 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2649 _call_for_each_replica\n        return fn(*args, **kwargs)\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1057 predict_step  **\n        return self(x, training=False)\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:884 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    c:\\program files\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_2 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 16]\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (35038,16) (8,) (35038,16) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-131-87d446ef3e68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# invert scaling for forecast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mpred_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_inv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mpred_inv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_inv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python38\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    434\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (35038,16) (8,) (35038,16) "
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[2]))\n",
    "\n",
    "# invert scaling for forecast\n",
    "pred_inv = np.concatenate((pred, X_test[:, 1:]), axis=1)\n",
    "pred_inv = scaler.inverse_transform(pred_inv)\n",
    "pred_inv = pred_inv[:,0]\n",
    "\n",
    "# invert scaling for actual\n",
    "y_test = y_test.reshape((len(y_test), 1))\n",
    "y_inv = np.concatenate((y_test, X_test[:, 1:]), axis=1)\n",
    "y_inv = scaler.inverse_transform(y_inv)\n",
    "y_inv = y_inv[:,0]\n",
    "print(y_inv)\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(y_inv, pred_inv))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35034</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35035</th>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35036</th>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35037</th>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35038</th>\n",
       "      <td>12.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35039 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       real  pred\n",
       "0      31.0  34.0\n",
       "1      20.0  29.0\n",
       "2      19.0  19.0\n",
       "3      18.0  18.0\n",
       "4      17.0  17.0\n",
       "...     ...   ...\n",
       "35034   8.0   9.0\n",
       "35035  10.0   7.0\n",
       "35036  10.0   9.0\n",
       "35037   8.0   9.0\n",
       "35038  12.0   7.0\n",
       "\n",
       "[35039 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(y_inv, columns=['real'])\n",
    "res['pred'] = np.round(pred_inv)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credits & Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
