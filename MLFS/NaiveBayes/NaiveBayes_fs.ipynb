{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes from scratch\n",
    "### From scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " ![](img/naivebayes1.png)\n",
    " ![](img/naivebayes2.png)\n",
    " \n",
    " ###   Six steps:\n",
    " ##### 1. Group rows by class : split the dataset in row groups one for each class.\n",
    " ##### 2. Take column statistics : mean, stdev and count to apply Bayes formula.\n",
    " ##### 3. Take column statistics by class : put steps 1 and 2 together.\n",
    " ##### 4. Buid Gaussian PDF : Gaussian PDF based on statistics calculated for each feature.\n",
    " ##### 5. Class probabilities: Probabilities of a piece of data belonging to a class based on Bayes formula.\n",
    " ##### 6. Prediction: Using all above do calculate predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "from csv import reader\n",
    "import sklearn.model_selection as skms   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Group rows by class\n",
    "We group the rows of the dataset by class in order to calculate the probability of data by the class they belong to (base rate).  \n",
    "To do so, we create a dictionary object where each key is the class and the value is a list of all the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_rows_by_class(dataset):\n",
    "    groups = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        class_value = vector[-1]\n",
    "        if (class_value not in groups):\n",
    "            groups[class_value] = list()\n",
    "        groups[class_value].append(vector)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test separating dataset rows by class\n",
    "dataset = [[3.393533211,2.331273381,0], [3.110073483,1.781539638,0], [1.343808831,3.368360954,0], [3.582294042,4.67917911,0], [2.280362439,2.866990263,0], [7.423436942,4.696522875,1], [5.745051997,3.533989803,1], [9.172168622,2.511101045,1], [7.792783481,3.424088941,1], [7.939820817,0.791637231,1]]\n",
    "groups = group_rows_by_class(dataset)\n",
    "for label in groups:\n",
    "    print(label)\n",
    "    for row in groups[label]:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Take column statistics\n",
    "We require statistics: the mean, standard deviation and count. We will use these to calculate normal distribution of data for each column (no interactions, thus naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean, stdev and count for each column in a dataset (except label)\n",
    "def col_stats(dataset):\n",
    "    stats = [(np.mean(column), np.std(column), len(column)) for column in zip(*dataset)]\n",
    "    del(stats[-1]) # delete statistics on the class (not needed)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test taking column statistics\n",
    "dataset = [[3.393533211,2.331273381,0], [3.110073483,1.781539638,0], [1.343808831,3.368360954,0], [3.582294042,4.67917911,0], [2.280362439,2.866990263,0], [7.423436942,4.696522875,1], [5.745051997,3.533989803,1], [9.172168622,2.511101045,1], [7.792783481,3.424088941,1], [7.939820817,0.791637231,1]]\n",
    "summary = col_stats(dataset)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Column stats by class  \n",
    "Above, we have developed the group_rows_by_class() and the stats_by_column(). We can put all of this together and summarize the columns in the dataset organized by class values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset by class then calculate statistics for each group of rows\n",
    "def col_stats_by_class(dataset):\n",
    "    row_groups = group_rows_by_class(dataset)\n",
    "    stats = dict()\n",
    "    for clasS, rows in row_groups.items():\n",
    "        stats[clasS] = col_stats(rows)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test column statistics by class\n",
    "dataset = [[3.393533211,2.331273381,0], [3.110073483,1.781539638,0], [1.343808831,3.368360954,0], [3.582294042,4.67917911,0], [2.280362439,2.866990263,0], [7.423436942,4.696522875,1], [5.745051997,3.533989803,1], [9.172168622,2.511101045,1], [7.792783481,3.424088941,1], [7.939820817,0.791637231,1]]\n",
    "csbc = col_stats_by_class(dataset)\n",
    "for label in csbc:\n",
    "    print(label, ':')\n",
    "    for row in csbc[label]:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Build Gaussian PDF  \n",
    "Calculating the probability or likelihood of observing a given real-value like X1 assuming normality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gaussian probability distribution function for x\n",
    "def prob(x, mean, stdev):\n",
    "    exponent = math.exp(-((x-mean)**2 / (2 * stdev**2 )))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Gaussian PDF\n",
    "print(prob(1.0, 1.0, 1.0))\n",
    "print(prob(2.0, 1.0, 1.0))\n",
    "print(prob(0.0, 1.0, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Class probabilities\n",
    "The probability that a piece of data belongs to a class. Remember Bayes formula is : P(class|data) = P(X|class) * P(class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(csbc, row):\n",
    "    total_rows = sum([csbc[label][0][2] for label in csbc]) # sum of counts\n",
    "    probs = dict()\n",
    "    for clasS, class_stats in csbc.items():\n",
    "        print('class: ', clasS)\n",
    "        print('class_stats: ', class_stats) # one class_stat per column (except labels)\n",
    "        Pclass = csbc[clasS][0][2] / float(total_rows) # rows count of class / all rows = P(class)\n",
    "        probs[clasS] = Pclass\n",
    "        for i in range(len(class_stats)):\n",
    "            mean, stdev, count = class_stats[i]\n",
    "            PXclass = prob(row[i], mean, stdev) # Probability of this row belonging to that class knowing the column value row[i] and given the distribution for that column and class P(X|class). \n",
    "            probs[clasS] *= PXclass # Same for each column, then product (naive). And multiply by the P(X|class) so that we have P(X|class) * P(class)\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test calculating class probabilities (probability of belonging to each of the classes)\n",
    "dataset = [[3.393533211,2.331273381,0], [3.110073483,1.781539638,0], [1.343808831,3.368360954,0], [3.582294042,4.67917911,0], [2.280362439,2.866990263,0], [7.423436942,4.696522875,1], [5.745051997,3.533989803,1], [9.172168622,2.511101045,1], [7.792783481,3.424088941,1], [7.939820817,0.791637231,1]]\n",
    "csbc = col_stats_by_class(dataset)\n",
    "probs = calculate_class_probabilities(csbc, dataset[0])\n",
    "print(probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class for a given row\n",
    "def nb_predict(csbc, row):\n",
    "    probs = calculate_class_probabilities(csbc, row)\n",
    "    best_class, best_prob = None, -1\n",
    "    for clasS, prob in probs.items():\n",
    "        if best_class is None or prob > best_prob:\n",
    "            best_prob = prob\n",
    "            best_class = clasS\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes on Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a CSV file\n",
    "def load_csv(filename):\n",
    "    header = True\n",
    "    dataset = list()\n",
    "    with open(filename, 'r') as file:\n",
    "        csv_reader = reader(file)\n",
    "        for row in csv_reader:\n",
    "            if not row:\n",
    "                continue\n",
    "            if header:\n",
    "                header = False\n",
    "                continue\n",
    "            dataset.append(row)\n",
    "    return dataset\n",
    "\n",
    "# Convert string column to float\n",
    "def str_column_to_float(dataset, column):\n",
    "    for row in dataset:\n",
    "        row[column] = float(row[column].strip())\n",
    "\n",
    "# Convert string column to integer\n",
    "def str_column_to_int(dataset, column):\n",
    "    class_values = [row[column] for row in dataset]\n",
    "    unique = set(class_values)\n",
    "    lookup = dict()\n",
    "    for i, value in enumerate(unique):\n",
    "        lookup[value] = i\n",
    "    for row in dataset:\n",
    "        row[column] = lookup[row[column]]\n",
    "    return lookup\n",
    "\n",
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, n_folds):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    fold_size = int(len(dataset) / n_folds)\n",
    "    for _ in range(n_folds):\n",
    "        fold = list()\n",
    "        while len(fold) < fold_size:\n",
    "            index = random.randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "def accuracy_metric(actual, predicted):\n",
    "    correct = 0\n",
    "    for i in range(len(actual)):\n",
    "        if actual[i] == predicted[i]:\n",
    "            correct += 1\n",
    "    return correct / float(len(actual)) * 100.0\n",
    "\n",
    "# Evaluate an algorithm using a cross validation split\n",
    "def evaluate_algorithm(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores\n",
    "\n",
    "\n",
    "# Naive Bayes Algorithm\n",
    "def naive_bayes(train, test):\n",
    "    csbc = col_stats_by_class(train)\n",
    "    preds = list()\n",
    "    for row in test:\n",
    "        output = nb_predict(csbc, row)\n",
    "        preds.append(output)\n",
    "    return(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Naive Bayes on Iris Dataset\n",
    "random.seed(1)\n",
    "filename = 'D:/data/csv/iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "    \n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "scores = evaluate_algorithm(dataset, naive_bayes, n_folds)\n",
    "print('Scores: ', scores)\n",
    "print( 'Mean Accuracy:', sum(scores)/float(len(scores)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Other distributions\n",
    "\n",
    "- Non-normal distributions  (Bernouilli, Multinomial)\n",
    "- Empyrical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Log probabilities\n",
    "A way to mitigate the vanishing effect of probabilities as a result of many multiplications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits & Links\n",
    "\n",
    "Based on the following sources:\n",
    "    \n",
    "https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/  \n",
    "https://www.saedsayad.com/naive_bayesian.htm  \n",
    "https://slideplayer.com/slide/4996705/  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
